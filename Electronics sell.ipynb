{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05f5469",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "### This code snippet utilizes Pandas' read_csv function to load a dataset into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ed7f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "  TransactionID CustomerID CustomerDOB CustGender CustLocation  \\\n",
      "0            T1   C5841053     10/1/94       Male   JAMSHEDPUR   \n",
      "1            T2   C2142763      4/4/57     Female      JHAJJAR   \n",
      "2            T3   C4417068    26/11/96     Female       MUMBAI   \n",
      "3            T4   C5342380     14/9/73     Female       MUMBAI   \n",
      "4            T5   C9031234     24/3/88       Male  NAVI MUMBAI   \n",
      "\n",
      "   CustAccountBalance TransactionDate  TransactionTime  STATUS_ bplayer0  \\\n",
      "0            17819.05      2023-02-08           143207      1.0    Vayne   \n",
      "1             2270.69      2023-02-08           141858      1.0     Kled   \n",
      "2            17874.44      2023-02-08           142712      1.0   Darius   \n",
      "3           866503.21      2023-02-08           142714      1.0   Singed   \n",
      "4             6714.43      2023-02-08           181156      1.0    Urgot   \n",
      "\n",
      "   product_id          category_id                        category_code  \\\n",
      "0     3900821  2053013552326770905  appliances.environment.water_heater   \n",
      "1     1307067  2053013558920217191                   computers.notebook   \n",
      "2     1004237  2053013555631882655               electronics.smartphone   \n",
      "3     1480613  2053013561092866779                    computers.desktop   \n",
      "4    28719074  2053013565480109009                   apparel.shoes.keds   \n",
      "\n",
      "    brand    price       PaymentMode  Frequency  \n",
      "0    aqua   2988.0       Credit Card    Monthly  \n",
      "1  lenovo  22656.6    Online Payment    Monthly  \n",
      "2   apple  97378.2    Online Payment  Bi-weekly  \n",
      "3  pulser  81775.8       Credit Card     Weekly  \n",
      "4   baden   9243.9  Cash on Delivery    Monthly  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path to your dataset\n",
    "file_path = 'Mistral.csv'\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c3debe",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "### Handling missing values,Handling duplicates,Reset index after dropping rows,Print the first few rows of the cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f5712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset:\n",
      "  TransactionID CustomerID CustomerDOB CustGender CustLocation  \\\n",
      "0            T1   C5841053     10/1/94       Male   JAMSHEDPUR   \n",
      "1            T2   C2142763      4/4/57     Female      JHAJJAR   \n",
      "2            T3   C4417068    26/11/96     Female       MUMBAI   \n",
      "3            T4   C5342380     14/9/73     Female       MUMBAI   \n",
      "4            T5   C9031234     24/3/88       Male  NAVI MUMBAI   \n",
      "\n",
      "   CustAccountBalance TransactionDate  TransactionTime  STATUS_ bplayer0  \\\n",
      "0            17819.05      2023-02-08           143207      1.0    Vayne   \n",
      "1             2270.69      2023-02-08           141858      1.0     Kled   \n",
      "2            17874.44      2023-02-08           142712      1.0   Darius   \n",
      "3           866503.21      2023-02-08           142714      1.0   Singed   \n",
      "4             6714.43      2023-02-08           181156      1.0    Urgot   \n",
      "\n",
      "   product_id          category_id                        category_code  \\\n",
      "0     3900821  2053013552326770905  appliances.environment.water_heater   \n",
      "1     1307067  2053013558920217191                   computers.notebook   \n",
      "2     1004237  2053013555631882655               electronics.smartphone   \n",
      "3     1480613  2053013561092866779                    computers.desktop   \n",
      "4    28719074  2053013565480109009                   apparel.shoes.keds   \n",
      "\n",
      "    brand    price       PaymentMode  Frequency  \n",
      "0    aqua   2988.0       Credit Card    Monthly  \n",
      "1  lenovo  22656.6    Online Payment    Monthly  \n",
      "2   apple  97378.2    Online Payment  Bi-weekly  \n",
      "3  pulser  81775.8       Credit Card     Weekly  \n",
      "4   baden   9243.9  Cash on Delivery    Monthly  \n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Handling duplicates\n",
    "# Drop duplicate rows if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index after dropping rows\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the first few rows of the cleaned DataFrame\n",
    "print(\"Cleaned dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6c41f",
   "metadata": {},
   "source": [
    "### Retrieve dataset dimensions, construct descriptive info, and print it.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a7e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 994284 rows and 17 columns.\n"
     ]
    }
   ],
   "source": [
    "# Get the dimensions of the dataset\n",
    "num_rows, num_cols = df.shape\n",
    "\n",
    "# Prepare descriptive information about the dataset\n",
    "dataset_info = f\"Dataset contains {num_rows} rows and {num_cols} columns.\"\n",
    "\n",
    "# Print the dataset information\n",
    "print(dataset_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1be67d",
   "metadata": {},
   "source": [
    "## Connect to a PostgreSQL database using psycopg2 in Python.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277a2417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'transaction_data_db' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "\n",
    "# Database connection parameters\n",
    "dbname = 'transaction_data_db'\n",
    "user = 'postgres'\n",
    "password = 'm123'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "\n",
    "# Connect to the default database (postgres) to create a new database\n",
    "conn = psycopg2.connect(dbname='postgres', user=user, password=password, host=host, port=port)\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create a new database if it doesn't exist\n",
    "cur.execute(f\"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{dbname}'\")\n",
    "exists = cur.fetchone()\n",
    "if not exists:\n",
    "    cur.execute(f\"CREATE DATABASE {dbname}\")\n",
    "    print(f\"Database '{dbname}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Database '{dbname}' already exists.\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e30e80",
   "metadata": {},
   "source": [
    "## Establish a connection to a PostgreSQL database using SQLAlchemy in Python.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bd7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Specify the PostgreSQL database connection URL\n",
    "db_url = f'postgresql://{user}:{password}@{host}:{port}/{dbname}'\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "engine = create_engine(db_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a6145",
   "metadata": {},
   "source": [
    "## Write DataFrame to a PostgreSQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1594fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully into PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the table name in the database\n",
    "table_name = 'transaction_data_table'\n",
    "\n",
    "# Write the DataFrame to the PostgreSQL database\n",
    "df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "# Print a message to confirm the data import\n",
    "print(\"Dataset loaded successfully into PostgreSQL database.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
